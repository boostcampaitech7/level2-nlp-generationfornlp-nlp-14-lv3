{
    "model_name_or_path": "beomi/gemma-ko-2b",
    "tokenizer_name": "beomi/gemma-ko-2b",
    "dataset_name": "../data/train.csv",
    "test_dataset_name": "../data/test.csv",
    "run_name": "baseline",
    "lora_r": 6,
    "lora_alpha": 8,
    "lora_dropout": 0.05,
    "predict_model_name_or_path": "",
    "test_size": 0.1,
    "do_train": true,
    "do_eval": true,
    "do_predict": true,
    "lr_scheduler_type": "cosine",
    "max_seq_length": 1024,
    "per_device_train_batch_size": 1,
    "per_device_eval_batch_size": 1,
    "num_train_epochs": 3,
    "learning_rate": 2e-5,
    "weight_decay": 0.01,
    "logging_steps": 1,
    "save_strategy": "epoch",
    "eval_strategy": "epoch",
    "save_total_limit": 2,
    "save_only_model": true,
    "report_to": "wandb",
    "seed": 42
}
